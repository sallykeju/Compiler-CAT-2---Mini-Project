{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## GROUP MEMBERS\n",
        "\n",
        "\n",
        "*   136243 Omondi Trevor Antony\n",
        "*   129197 Sally Keju\n",
        "*   120406 Allan Kirui Kiprono\n",
        "*   136444 Ethan Kanja\n",
        "*   134653 Cynthia Musila\n",
        "*   129097 Mary Aladwa\n",
        "*   136614 Abraham Zawadi\n",
        "\n"
      ],
      "metadata": {
        "id": "VdhYIHoEMCUV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QUESTION"
      ],
      "metadata": {
        "id": "1eWMOkV-ImDK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement any phase, component, element etc learned in the course thus far.\n",
        "\n",
        "Ideas can range from implementing a lexer, parser to generating your own language (i.e. CFG) etc.\n",
        "\n",
        "Whatever you implement make sure to describe your solution in detail by outlining its logic, concepts used among other relevant details."
      ],
      "metadata": {
        "id": "pMj6YboDIs3I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implementing a Lexer and Parser for a Simple Language**"
      ],
      "metadata": {
        "id": "YJQdQ6jXIayV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Description of Solution\n",
        "\n",
        "This solution implements a parser for a simple arithmetic expression language. The language consists of the following operators:\n",
        "\n",
        "Arithmetic operators: +, -, *, /\n",
        "Parentheses: ( and )\n",
        "The parser works by first tokenizing the expression into a list of tokens. Each token can be a number, an operator, or a parenthesis. The parser then recursively parses the list of tokens to construct an abstract syntax tree (AST). The AST represents the structure of the expression in a way that is easy to evaluate.\n",
        "\n",
        "The parser uses the following concepts from the course:\n",
        "\n",
        "\n",
        "*   Lexical analysis: The lexer splits the expression into a list of tokens.\n",
        "*   Syntactic analysis: The parser constructs an AST from the list of tokens.\n",
        "*   Recursive descent parsing: The parser recursively parses the list of tokens to construct the AST.\n",
        "*   Abstract syntax tree: The AST represents the structure of the expression in a way that is easy to evaluate.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HFof7b-KK889"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lexer**\n",
        "The lexer takes an expression as input and returns a list of tokens. The tokens are the basic building blocks of the expression, such as numbers, operators, and parentheses.\n",
        "\n",
        "The lexer logic is as follows:\n",
        "\n",
        "Initialize a regular expression to match the different types of tokens in the expression.\n",
        "Iterate over the expression and match the regular expression against each character.\n",
        "If a match is found, return the corresponding token.\n",
        "If no match is found, raise an error."
      ],
      "metadata": {
        "id": "A42gtBqxIsSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Lexer\n",
        "def lexer(expression):\n",
        "  tokens = re.findall(r'\\d+|\\+|\\-|\\*|\\/|\\(|\\)', expression)\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "YAqSAI6-I6D9"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This regular expression matches the following types of tokens:\n",
        "\n",
        "Numbers (\\d+)\n",
        "Operators (+, -, *, /)\n",
        "Parentheses ((, ))"
      ],
      "metadata": {
        "id": "jj8JPVGvJA-A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Parser**\n",
        "The parser takes a list of tokens from the lexer and returns an abstract syntax tree (AST). The AST is a tree-like representation of the expression, with each node in the tree representing a different part of the expression, such as a number, an operator, or a subexpression.\n",
        "\n",
        "**Parser logic**\n",
        "\n",
        "Initialize a stack to store the current state of the parse.\n",
        "Iterate over the list of tokens.\n",
        "For each token, perform the following:\n",
        "If the token is a number, push a number node onto the stack.\n",
        "If the token is an operator, pop two nodes off the stack and push a binary operator node onto the stack, with the two popped nodes as its children.\n",
        "If the token is a left parenthesis, push a left parenthesis node onto the stack.\n",
        "If the token is a right parenthesis, pop a node off the stack and check if it is a left parenthesis node. If it is, then the subexpression has been parsed and the popped node can be discarded. Otherwise, raise an error.\n",
        "Once all of the tokens have been processed, the stack should contain only a single node, which is the root of the AST."
      ],
      "metadata": {
        "id": "S9gHUGRkJGjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse(tokens):\n",
        "  index = 0\n",
        "\n",
        "  def expression():\n",
        "    nonlocal index\n",
        "    left = term()\n",
        "\n",
        "    while index < len(tokens) and tokens[index] in ('+', '-'):\n",
        "      operator = tokens[index]\n",
        "      index += 1\n",
        "      right = term()\n",
        "      left = (operator, left, right)\n",
        "\n",
        "    return left\n",
        "\n",
        "  def term():\n",
        "    nonlocal index\n",
        "    left = factor()\n",
        "\n",
        "    while index < len(tokens) and tokens[index] in ('*', '/'):\n",
        "      operator = tokens[index]\n",
        "      index += 1\n",
        "      right = factor()\n",
        "      left = (operator, left, right)\n",
        "\n",
        "    return left\n",
        "\n",
        "  def factor():\n",
        "    nonlocal index\n",
        "    token = tokens[index]\n",
        "    index += 1\n",
        "\n",
        "    if token.isdigit():\n",
        "      return int(token)\n",
        "    elif token == '(':\n",
        "      result = expression()\n",
        "      index += 1\n",
        "      return result\n",
        "\n",
        "  return expression()"
      ],
      "metadata": {
        "id": "wgTUotamJaMJ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This parser implements the following concepts:\n",
        "*   **Top-down parsing**: The parser starts by parsing the top-level expression and\n",
        "then recursively parses the subexpressions.\n",
        "Recursive descent parsing: The parser recursively calls itself to parse the subexpressions.\n",
        "*   **Operator precedence**: The parser uses operator precedence to determine the\n",
        "order in which the operators should be evaluated.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nzDnromRJeqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(ast):\n",
        "  if isinstance(ast, int):\n",
        "    return ast\n",
        "\n",
        "  operator, left, right = ast\n",
        "\n",
        "  if operator == '+':\n",
        "    return evaluate(left) + evaluate(right)\n",
        "  elif operator == '-':\n",
        "    return evaluate(left) - evaluate(right)\n",
        "  elif operator == '*':\n",
        "    return evaluate(left) * evaluate(right)\n",
        "  elif operator == '/':\n",
        "    return evaluate(left) / evaluate(right)"
      ],
      "metadata": {
        "id": "NmFpeNwQKN4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXAMPLE**\n",
        "Here is an example of how to use the lexer and parser to parse a simple expression:"
      ],
      "metadata": {
        "id": "kCqSuQTLJ0I1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "expression = \"2 + 3 * (4 - 1)\"\n",
        "tokens = lexer(expression)\n",
        "ast = parse(tokens)\n",
        "result = evaluate(ast)\n",
        "print(f\"The result of the expression '{expression}' is: {result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lSCrozuHqtC",
        "outputId": "3733692d-0622-4db8-f7bf-78a3eeb6b72b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The result of the expression '2 + 3 * (4 - 1)' is: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **OUTPUT**\n",
        "From the expression: 2 + 3 * (4 - 1)\n",
        "\n",
        "The result of the expression '2 + 3 * (4 - 1)' is: 11"
      ],
      "metadata": {
        "id": "C2E2q1w5Khy8"
      }
    }
  ]
}